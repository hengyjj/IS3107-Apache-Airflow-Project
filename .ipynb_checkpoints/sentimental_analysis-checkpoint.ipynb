{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0822daa853214f6597183c8f4e197368",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "cell_id": "1f9e6a66631542d9a761cb285cead934",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1680427262817,
    "source_hash": "c8932205"
   },
   "outputs": [],
   "source": [
    "################## Codes For Testing ##################\n",
    "# Printing first 5 rows\n",
    "# hotel_reviews_df = hotel_reviews_df[[\"review\", \"cleaned_review\"]]\n",
    "# print(hotel_reviews_df.head()) \n",
    "\n",
    "# Uncomment the below two codes to get a smaller csv file (input the column that you wish to check)\n",
    "# hotel_reviews_df = hotel_reviews_df[[\"review\", \"cleaned_review\"]]\n",
    "# hotel_reviews_df.to_csv('hotel_reviews_df_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a43fa8ff63c647f3aca08c559bdd3d89",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42650,
    "execution_start": 1680427262818,
    "source_hash": "c350f1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: regex in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: wordcloud in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (1.8.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.3.2)\n",
      "Requirement already satisfied: pillow in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: six in /Users/yijie/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#1. This step will add a new column called sentiments to classify the reviews based on four scores: \n",
    "# neutrality, positivity, negativity and overall scores that descrbies the previous three scores.\n",
    "!pip install nltk\n",
    "!pip install wordcloud\n",
    "!pip install gensim\n",
    "!pip install pandas\n",
    "import nltk \n",
    "nltk.download('popular')\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hotel_reviews_df_cleaned = pd.read_csv(\"hotel_reviews_df_cleaned.csv\")\n",
    "\n",
    "# IMPORTANT *** Extract out only this 3 columns because this is all what we need for ML\n",
    "hotel_reviews_df_cleaned = hotel_reviews_df_cleaned[[\"review\", \"is_bad_review\", \"cleaned_review\"]]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "hotel_reviews_df_cleaned[\"sentiments\"] = hotel_reviews_df_cleaned[\"review\"].apply(lambda review: sid.polarity_scores(str(review)))\n",
    "\n",
    "hotel_reviews_df_cleaned = pd.concat([hotel_reviews_df_cleaned.drop(['sentiments'], axis=1), hotel_reviews_df_cleaned['sentiments'].apply(pd.Series)], axis=1)\n",
    "\n",
    "hotel_reviews_df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "bc644d8a2a514a27b38703db92deaf33",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 298,
    "execution_start": 1680427305470,
    "source_hash": "3833fc6b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hotel_reviews_df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1c3fdb8cbc02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#2. This will add 2 more new columns, the number of character and number of words column based on each corresponding review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhotel_reviews_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_chars\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotel_reviews_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhotel_reviews_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_words\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhotel_reviews_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hotel_reviews_df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "#2. This will add 2 more new columns, the number of character and number of words column based on each corresponding review\n",
    "\n",
    "hotel_reviews_df_cleaned[\"num_chars\"] = hotel_reviews_df_cleaned[\"review\"].apply(lambda x: len(str(x)))\n",
    "hotel_reviews_df_cleaned[\"num_words\"] = hotel_reviews_df_cleaned[\"review\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "hotel_reviews_df_cleaned.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "02fbd6e3252c4748a0d45bb12bceb742",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 111328,
    "execution_start": 1680427305826,
    "source_hash": "9e73aad"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hotel_reviews_df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0301325dfab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create tagged documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtagged_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotel_reviews_df_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cleaned_review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(hotel_reviews_df_cleaned[\"cleaned_review\"].apply(lambda x: str(x).split(\" \")))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#Train the Doc2Vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hotel_reviews_df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "#3. Create doc2vec vector columns\n",
    "# It is using the gensim library to create a Doc2Vec model and apply it to the cleaned review texts, \n",
    "# then concatenating the resulting vectors with the original DataFrame to create new columns.\n",
    "# Doc2Vec is an unsupervised machine learning algorithm that learns fixed-length vector representations \n",
    "# (embeddings) from variable-length pieces of texts, such as documents, paragraphs, or sentences. \n",
    "# These embeddings can be used for tasks like text classification, clustering, and similarity matching. \n",
    "# Doc2Vec is an extension of Word2Vec, which learns embeddings for individual words. \n",
    "# Unlike Word2Vec, Doc2Vec learns a separate embedding for each document, while still taking into account \n",
    "# the words in the document.\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Create tagged documents\n",
    "tagged_documents = [TaggedDocument(str(review).split(\" \"), [i]) for i, review in enumerate(hotel_reviews_df_cleaned[\"cleaned_review\"])]\n",
    "# tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(hotel_reviews_df_cleaned[\"cleaned_review\"].apply(lambda x: str(x).split(\" \")))]\n",
    "#Train the Doc2Vec model\n",
    "model = Doc2Vec(tagged_documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "#Infer vectors for each document\n",
    "doc2vec_df = pd.DataFrame([model.infer_vector(str(review).split(\" \")) for review in hotel_reviews_df_cleaned[\"cleaned_review\"]])\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(i) for i in range(doc2vec_df.shape[1])]\n",
    "\n",
    "# Concatenate the Doc2Vec vector with the original df\n",
    "hotel_reviews_df_cleaned = pd.concat([hotel_reviews_df_cleaned, doc2vec_df], axis=1)\n",
    "\n",
    "hotel_reviews_df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7c87a9a816c147fcaf1315adf8c55d7b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6478,
    "execution_start": 1680427417153,
    "source_hash": "2d8aec33"
   },
   "outputs": [],
   "source": [
    "#4. Create TF-IDFS columns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer with a minimum document frequency of 10\n",
    "tfidf = TfidfVectorizer(min_df=10)\n",
    "\n",
    "# # Fit the vectorizer to the cleaned reviews and transform the text into a matrix of TF-IDF features\n",
    "hotel_reviews_df_cleaned[\"cleaned_review\"] = hotel_reviews_df_cleaned[\"cleaned_review\"].fillna(\"\")\n",
    "tfidf_result = tfidf.fit_transform(hotel_reviews_df_cleaned[\"cleaned_review\"])\n",
    "\n",
    "\n",
    "# # Convert the result to a pandas DataFrame with the feature names as column headers\n",
    "tfidf_df = pd.DataFrame(tfidf_result.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# # Add a prefix to each column name for identification purposes\n",
    "tfidf_df = tfidf_df.add_prefix('word_')\n",
    "\n",
    "# # Concatenate the original dataframe with the TF-IDF matrix\n",
    "hotel_reviews_df_cleaned = pd.concat([hotel_reviews_df_cleaned, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c4d2387d64b94767a97453c06c81c402",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1680427423636,
    "source_hash": "42b5b00f"
   },
   "outputs": [],
   "source": [
    "#5. Interested to find out the percentage of the dataset that is considered a bad review and good review\n",
    "# This will help us see whether the dataset is balanced or imbalance, and further understand the skewness\n",
    "total_Bad_Reviews = \"is_bad_review\"\n",
    "results = hotel_reviews_df_cleaned[total_Bad_Reviews].value_counts()\n",
    "\n",
    "#Get total reviews in the data set\n",
    "#Query the bad reviews / total reviews * 100% to get percentage of bad reviews same for good reviews\n",
    "totalReviews = results[0] + results[1]\n",
    "goodReview = results[0]\n",
    "badReview = results[1]\n",
    "numOfBadReviews = badReview / totalReviews\n",
    "print(round(numOfBadReviews, 3) * 100)\n",
    "\n",
    "numOfGoodReviews = goodReview / totalReviews\n",
    "print(round(numOfGoodReviews, 3) * 100)\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "#From this we can see that the only 4.3% of the reviews given are bad and 95.7% are good.\n",
    "#Dataset is not balanced but also can be used an indicator for client to know that they are doing a good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "efde04339de24a5da73366fa3d958c36",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 843,
    "execution_start": 1680427423647,
    "source_hash": "6e11edce"
   },
   "outputs": [],
   "source": [
    "#6. Interested to find out the most used words in the reviews, regardless of good or bad\n",
    "# This helps the client to see what is the sentiment about the hotel among previous guest\n",
    "#Examples are \"Expensive\" which could indicate the per night prices are too high and or\n",
    "#Small, which could indicate the rooms are too small. \n",
    "#Further investigation would be needed\n",
    "\n",
    "def generateWordCloud(data, title = None):\n",
    "    \n",
    "    interestedData = str(data)\n",
    "    \n",
    "    wordCloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 400,\n",
    "        max_font_size = 40, \n",
    "        scale = 3, \n",
    "        random_state = 42\n",
    "    ).generate(interestedData)\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordCloud)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "criteria = \"review\"\n",
    "allHotelData = hotel_reviews_df_cleaned[criteria]\n",
    "generateWordCloud(allHotelData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2b1df4b409da4fb4ac857c94434d780c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29785,
    "execution_start": 1680427424483,
    "source_hash": "4446728f"
   },
   "outputs": [],
   "source": [
    "# hotel_reviews_df_cleaned = hotel_reviews_df_cleaned[[\"review\", \"pos\"]]\n",
    "# hotel_reviews_df_cleaned.head()\n",
    "\n",
    "#7. Get the first 10 highest reviews with a positive Sentiment\n",
    "totalNumOfWords = hotel_reviews_df_cleaned[\"num_words\"] \n",
    "totalNumOfWordsAboveFive = totalNumOfWords >= 5\n",
    "\n",
    "getTotalNumOfWordsAboveFive = hotel_reviews_df_cleaned[totalNumOfWordsAboveFive]\n",
    "getSortedPositiveValue = getTotalNumOfWordsAboveFive.sort_values(\"pos\", ascending = False)[[\"review\", \"pos\"]].head(10)\n",
    "print(getSortedPositiveValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Get the first 10 highest reviews with a Negative Sentiment\n",
    "totalNumOfWords = hotel_reviews_df_cleaned[\"num_words\"]\n",
    "totalNumOfWordsAboveFive = totalNumOfWords >= 5\n",
    "\n",
    "getTotalNumOfWordsAboveFive = hotel_reviews_df_cleaned[totalNumOfWordsAboveFive]\n",
    "getSortedPositiveValue = getTotalNumOfWordsAboveFive.sort_values(\"neg\", ascending = False)[[\"review\", \"neg\"]].head(10)\n",
    "print(getSortedPositiveValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Plot sentiment distribution for positive and negative reviews\n",
    "for label, is_bad_review in [(\"Good reviews\", 0), (\"Bad reviews\", 1)]:\n",
    "    reviewToPlot = is_bad_review\n",
    "    badReview = hotel_reviews_df_cleaned['is_bad_review'] == reviewToPlot\n",
    "    group = hotel_reviews_df_cleaned[badReview]\n",
    "    \n",
    "    sns.histplot(group['compound'], kde = True, label = label)\n",
    "    sns.displot(group['compound'], label = label, kind = \"kde\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Modeling Reviewer Score\n",
    "\n",
    "# Feature selection\n",
    "label = \"is_bad_review\"\n",
    "ignore_cols = [label, \"review\", \"cleaned_review\"]\n",
    "\n",
    "features = [c for c in hotel_reviews_df_cleaned.columns if c not in ignore_cols]\n",
    "\n",
    "# split the data into train and test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hotel_reviews_df_cleaned[features], hotel_reviews_df_cleaned[label], test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ea4e772d-4daa-4712-9df2-11ccbdb38015' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e5097515906d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#11. Train a random forest classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#12. Show feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#11. Train a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#12. Show feature importance\n",
    "feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\n",
    "feature_importances_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "c1f74be647ac45c691ce51e5ef2770b9",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
